diff --git a/hw/rtl/VX_gpu_pkg.sv b/hw/rtl/VX_gpu_pkg.sv
index fe35fb3..465bbb0 100644
--- a/hw/rtl/VX_gpu_pkg.sv
+++ b/hw/rtl/VX_gpu_pkg.sv
@@ -82,6 +82,8 @@ package VX_gpu_pkg;
     typedef struct packed {
         logic [`PERF_CTR_BITS-1:0] idles;
         logic [`PERF_CTR_BITS-1:0] stalls;
+        logic [`PERF_CTR_BITS-1:0] active_threads;
+        logic [`PERF_CTR_BITS-1:0] sched_fires;
     } sched_perf_t;
 
     typedef struct packed {
diff --git a/hw/rtl/VX_types.vh b/hw/rtl/VX_types.vh
index 048ba0a..e96c2e8 100644
--- a/hw/rtl/VX_types.vh
+++ b/hw/rtl/VX_types.vh
@@ -110,6 +110,10 @@
 `define VX_CSR_MPM_IFETCH_LT_H          12'hB91
 `define VX_CSR_MPM_LOAD_LT              12'hB12
 `define VX_CSR_MPM_LOAD_LT_H            12'hB92
+`define VX_CSR_MPM_ACTIVE_THREADS_LT    12'hB13
+`define VX_CSR_MPM_ACTIVE_THREADS_LT_H  12'hB93
+`define VX_CSR_MPM_SCHED_FIRES_LT       12'hB14
+`define VX_CSR_MPM_SCHED_FIRES_LT_H     12'hB94
 
 // Machine Performance-monitoring memory counters (class 2) ///////////////////
 
diff --git a/hw/rtl/core/VX_csr_data.sv b/hw/rtl/core/VX_csr_data.sv
index 68bf7f7..32e5003 100644
--- a/hw/rtl/core/VX_csr_data.sv
+++ b/hw/rtl/core/VX_csr_data.sv
@@ -233,6 +233,8 @@ import VX_fpu_pkg::*;
                         `CSR_READ_64(`VX_CSR_MPM_STORES, read_data_ro_w, pipeline_perf_if.stores);
                         `CSR_READ_64(`VX_CSR_MPM_IFETCH_LT, read_data_ro_w, pipeline_perf_if.ifetch_latency);
                         `CSR_READ_64(`VX_CSR_MPM_LOAD_LT, read_data_ro_w, pipeline_perf_if.load_latency);
+                        `CSR_READ_64(`VX_CSR_MPM_ACTIVE_THREADS_LT, read_data_ro_w, pipeline_perf_if.sched.active_threads);
+                        `CSR_READ_64(`VX_CSR_MPM_SCHED_FIRES_LT, read_data_ro_w, pipeline_perf_if.sched.sched_fires);
                         default:;
                         endcase
                     end
diff --git a/hw/rtl/core/VX_schedule.sv b/hw/rtl/core/VX_schedule.sv
index 9b49ae2..7f1e4f3 100644
--- a/hw/rtl/core/VX_schedule.sv
+++ b/hw/rtl/core/VX_schedule.sv
@@ -382,7 +382,7 @@ module VX_schedule import VX_gpu_pkg::*; #(
             `UNUSED_PIN (alm_full),
             `UNUSED_PIN (size)
         );
-	end
+    end
 
     assign sched_csr_if.alm_empty = pending_warp_alm_empty[sched_csr_if.alm_empty_wid];
 
@@ -418,22 +418,41 @@ module VX_schedule import VX_gpu_pkg::*; #(
 `ifdef PERF_ENABLE
     reg [`PERF_CTR_BITS-1:0] perf_sched_idles;
     reg [`PERF_CTR_BITS-1:0] perf_sched_stalls;
+    reg [`PERF_CTR_BITS-1:0] perf_sched_active_threads;
+    reg [`PERF_CTR_BITS-1:0] perf_sched_sched_fires;
 
     wire schedule_idle = ~schedule_valid;
     wire schedule_stall = schedule_if.valid && ~schedule_if.ready;
+    wire [`NUM_THREADS-1:0] sched_tmask = schedule_if.data.tmask;
+
+    wire [`CLOG2(`NUM_THREADS+1)-1:0] active_threads_cnt;
+    `POP_COUNT(active_threads_cnt, sched_tmask);
 
     always @(posedge clk) begin
         if (reset) begin
             perf_sched_idles  <= '0;
             perf_sched_stalls <= '0;
+            perf_sched_active_threads <= '0;
+            perf_sched_sched_fires <= '0;
         end else begin
             perf_sched_idles  <= perf_sched_idles + `PERF_CTR_BITS'(schedule_idle);
             perf_sched_stalls <= perf_sched_stalls + `PERF_CTR_BITS'(schedule_stall);
+
+            // update active warp counter whenever new warp is scheduled
+            if (schedule_if_fire) begin
+                perf_sched_sched_fires <= perf_sched_sched_fires + `PERF_CTR_BITS'(1);
+                perf_sched_active_threads <= perf_sched_active_threads + `PERF_CTR_BITS'(active_threads_cnt);
+            end else begin
+                perf_sched_sched_fires <= perf_sched_sched_fires;
+                perf_sched_active_threads <= perf_sched_active_threads;
+            end   
         end
     end
 
     assign sched_perf.idles = perf_sched_idles;
     assign sched_perf.stalls = perf_sched_stalls;
+    assign sched_perf.active_threads = perf_sched_active_threads;
+    assign sched_perf.sched_fires = perf_sched_sched_fires;
 `endif
 
 endmodule
diff --git a/runtime/stub/utils.cpp b/runtime/stub/utils.cpp
index c1f75f0..953e286 100644
--- a/runtime/stub/utils.cpp
+++ b/runtime/stub/utils.cpp
@@ -180,6 +180,7 @@ extern int vx_dump_perf(vx_device_h hdevice, FILE* stream) {
   // PERF: pipeline stalls
   uint64_t sched_idles = 0;
   uint64_t sched_stalls = 0;
+  uint64_t sched_warp_eff = 0;
   uint64_t ibuffer_stalls = 0;
   uint64_t scrb_stalls = 0;
   uint64_t opds_stalls = 0;
@@ -275,6 +276,32 @@ extern int vx_dump_perf(vx_device_h hdevice, FILE* stream) {
         }
         sched_stalls += sched_stalls_per_core;
       }
+      // warp execution efficiency
+      {
+        // utilities for warp execution efficiency counter
+        uint64_t warps_per_core, threads_per_warp;
+        CHECK_ERR(vx_dev_caps(hdevice, VX_CAPS_NUM_WARPS, &warps_per_core), {
+          return err;
+        });
+        CHECK_ERR(vx_dev_caps(hdevice, VX_CAPS_NUM_THREADS, &threads_per_warp), {
+          return err;
+        });
+        uint32_t threads_per_core = warps_per_core * threads_per_warp;
+        // warp execution efficiency counter
+        {
+          uint64_t active_threads_per_core;
+          CHECK_ERR(vx_mpm_query(hdevice, VX_CSR_MPM_ACTIVE_THREADS_LT, core_id, &active_threads_per_core), {
+            return err;
+          });
+          uint64_t sched_fires_per_core;
+          CHECK_ERR(vx_mpm_query(hdevice, VX_CSR_MPM_SCHED_FIRES_LT, core_id, &sched_fires_per_core), {
+            return err;
+          });
+          float warp_eff_percent_per_core = float(active_threads_per_core) / float(sched_fires_per_core) / float(threads_per_warp) * 100.0;
+          fprintf(stream, "PERF: core%d: threads/core=%d total activated threads=%ld total schedule fires=%ld scheduler warp efficiency=(%f%%)\n", core_id, threads_per_core, active_threads_per_core, sched_fires_per_core, warp_eff_percent_per_core);
+          sched_warp_eff += warp_eff_percent_per_core;
+        }
+      }
       // ibuffer stalls
       {
         uint64_t ibuffer_stalls_per_core;
@@ -563,6 +590,7 @@ extern int vx_dump_perf(vx_device_h hdevice, FILE* stream) {
   case VX_DCR_MPM_CLASS_CORE: {
     int sched_idles_percent = calcAvgPercent(sched_idles, total_cycles);
     int sched_stalls_percent = calcAvgPercent(sched_stalls, total_cycles);
+    int sched_warp_eff_percent = calcAvgPercent(sched_warp_eff, num_cores);
     int ibuffer_percent = calcAvgPercent(ibuffer_stalls, total_cycles);
     int scrb_percent = calcAvgPercent(scrb_stalls, total_cycles);
     int opds_percent = calcAvgPercent(opds_stalls, total_cycles);
@@ -571,6 +599,7 @@ extern int vx_dump_perf(vx_device_h hdevice, FILE* stream) {
     uint64_t scrb_total = scrb_alu + scrb_fpu + scrb_lsu + scrb_csrs + scrb_wctl;
     fprintf(stream, "PERF: scheduler idle=%ld (%d%%)\n", sched_idles, sched_idles_percent);
     fprintf(stream, "PERF: scheduler stalls=%ld (%d%%)\n", sched_stalls, sched_stalls_percent);
+    fprintf(stream, "PERF: scheduler warp efficiency=%ld (%d%%)\n", sched_warp_eff / num_cores, sched_warp_eff_percent);
     fprintf(stream, "PERF: ibuffer stalls=%ld (%d%%)\n", ibuffer_stalls, ibuffer_percent);
     fprintf(stream, "PERF: scoreboard stalls=%ld (%d%%) (alu=%d%%, fpu=%d%%, lsu=%d%%, csrs=%d%%, wctl=%d%%)\n"
       , scrb_stalls
diff --git a/tests/regression/sort/common.h b/tests/regression/sort/common.h
index 4ebfb74..bc7cd7b 100644
--- a/tests/regression/sort/common.h
+++ b/tests/regression/sort/common.h
@@ -9,6 +9,8 @@ typedef struct {
   uint32_t num_points;
   uint64_t src_addr;
   uint64_t dst_addr;  
+  uint32_t k;
+  uint32_t j;
 } kernel_arg_t;
 
 #endif
diff --git a/tests/regression/sort/kernel.cpp b/tests/regression/sort/kernel.cpp
index 8cd13c9..a9fe6d9 100644
--- a/tests/regression/sort/kernel.cpp
+++ b/tests/regression/sort/kernel.cpp
@@ -1,22 +1,85 @@
 #include <vx_spawn.h>
+#include <vx_intrinsics.h>
+#include <vx_print.h>
+#include <inttypes.h>
 #include "common.h"
 
+// Copy all data from source register to destination register
+void copy_reg(kernel_arg_t* __UNIFORM__ arg) {
+    uint32_t i = blockIdx.x;
+    uint32_t n = arg->num_points;
+    TYPE* src_ptr = (TYPE*)arg->src_addr;
+    TYPE* dst_ptr = (TYPE*)arg->dst_addr;
+
+    if (i < n) {
+        dst_ptr[i] = src_ptr[i];
+    }
+
+    vx_fence();
+    vx_barrier(0, vx_num_warps());           // Synchronize warps within a core
+}
+
+// Runs on each individual thread for bitonic sort
 void kernel_body(kernel_arg_t* __UNIFORM__ arg) {
-	uint32_t num_points = arg->num_points;
-	auto src_ptr = (TYPE*)arg->src_addr;
-	auto dst_ptr = (TYPE*)arg->dst_addr;
-
-	auto ref_value = src_ptr[blockIdx.x];
-
-	uint32_t pos = 0;
-	for (uint32_t i = 0; i < num_points; ++i) {
-		auto cur_value = src_ptr[i];
-		pos += (cur_value < ref_value) || ((cur_value == ref_value) && (i < blockIdx.x));
-	}
-	dst_ptr[pos] = ref_value;
+    uint32_t i = blockIdx.x;  
+    uint32_t n = arg->num_points;  
+    uint32_t k = arg->k;  // Pass number
+    uint32_t j = arg->j;  // Distance for comparison
+    TYPE* data_ptr = (TYPE*)arg->dst_addr;
+
+    if (i < n) {
+        uint32_t i_comp = i ^ j;  // Calculate comparison index
+
+        if (i_comp > i && i_comp < n) {
+            bool direction;
+            if ((i & k) == 0) {
+                direction = true;  // Ascending order
+            } else {
+                direction = false; // Descending order
+            }
+
+            // Comparison and swap logic (in-place)
+            if (direction) {
+                if (data_ptr[i] > data_ptr[i_comp]) {
+                    TYPE temp = data_ptr[i];
+                    data_ptr[i] = data_ptr[i_comp];
+                    data_ptr[i_comp] = temp;
+                } // else already ascending
+            } else {
+                if (data_ptr[i] < data_ptr[i_comp]) {
+                    TYPE temp = data_ptr[i];
+                    data_ptr[i] = data_ptr[i_comp];
+                    data_ptr[i_comp] = temp;
+                } // else already descending
+            }
+        }
+    }
+
+    vx_fence();
+    vx_barrier(0, vx_num_warps());           // Synchronize warps within a core
 }
 
 int main() {
-	kernel_arg_t* arg = (kernel_arg_t*)csr_read(VX_CSR_MSCRATCH);
-	return vx_spawn_threads(1, &arg->num_points, nullptr, (vx_kernel_func_cb)kernel_body, arg);
+    kernel_arg_t* arg = (kernel_arg_t*)csr_read(VX_CSR_MSCRATCH);
+    uint32_t n = arg->num_points;
+
+    // Copy data from src_ptr to dst_ptr
+    {
+        uint32_t num_blocks = n;
+        vx_spawn_threads(1, &num_blocks, nullptr, (vx_kernel_func_cb)copy_reg, arg);
+        vx_fence();  // Wait for all threads to complete
+    }
+
+    // Bitonic loop with in-place sorting
+    for (uint32_t k = 2; k <= n; k *= 2) {
+        for (uint32_t j = k / 2; j > 0; j /= 2) {
+            arg->k = k;
+            arg->j = j;
+
+            uint32_t num_blocks = n;
+            vx_spawn_threads(1, &num_blocks, nullptr, (vx_kernel_func_cb)kernel_body, arg);
+            vx_fence();  // Ensure all threads complete this pass
+            vx_barrier(0x80000000, vx_num_cores());  // Synchronize across all cores   
+        }
+    }
 }
